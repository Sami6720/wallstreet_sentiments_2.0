{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorations of the data that needs to be collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "import praw\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from datetime import date\n",
    "import schedule\n",
    "\n",
    "# stop warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''includes US stock symbols with market cap > 100 Million, and price above $3. \n",
    "Download the csv file:\n",
    "https://www.nasdaq.com/market-activity/stocks/screener?exchange=nasdaq&letter=0&render=download \n",
    "for all of the NYSE, NASDAQ and NYSEAMERICAN public traded companies.\n",
    "'''\n",
    "\n",
    "stocks = pd.read_csv('tickers.csv')\n",
    "\n",
    "# Last Sale column is an object, let's convert to float\n",
    "stocks['Last Sale'] = stocks['Last Sale'].str.replace('$', '')\n",
    "stocks['Last Sale'] = pd.to_numeric(stocks['Last Sale'], downcast='float')\n",
    "type(stocks['Last Sale'][0])\n",
    "\n",
    "# Filter out stocks >$3 and > $100 million cap\n",
    "price_filter = stocks['Last Sale'] >= 3.00\n",
    "cap_filter = stocks['Market Cap'] >= 100000000\n",
    "\n",
    "# make set of symbols\n",
    "stocks = set(stocks[(price_filter) & (cap_filter)]['Symbol'])\n",
    "\n",
    "# Includes common words and words used on wsb that are also stock names\n",
    "blacklist = {'I', 'ELON', 'WSB', 'THE', 'A', 'ROPE', 'YOLO', 'TOS', 'CEO', 'DD', 'IT', 'OPEN', 'ATH', 'PM', 'IRS', 'FOR','DEC', 'BE', 'IMO', 'ALL', 'RH', 'EV', 'TOS', 'CFO', 'CTO', 'DD', 'BTFD', 'WSB', 'OK', 'PDT', 'RH', 'KYS', 'FD', 'TYS', 'US', 'USA', 'IT', 'ATH', 'RIP', 'BMW', 'GDP', 'OTM', 'ATM', 'ITM', 'IMO', 'LOL', 'AM', 'BE', 'PR', 'PRAY', 'PT', 'FBI', 'SEC', 'GOD', 'NOT', 'POS', 'FOMO', 'TL;DR', 'EDIT', 'STILL', 'WTF', 'RAW', 'PM', 'LMAO', 'LMFAO', 'ROFL', 'EZ', 'RED', 'BEZOS', 'TICK', 'IS', 'PM', 'LPT', 'GOAT', 'FL', 'CA', 'IL', 'MACD', 'HQ', 'OP', 'PS', 'AH', 'TL', 'JAN', 'FEB', 'JUL', 'AUG', 'SEP', 'SEPT', 'OCT', 'NOV', 'FDA', 'IV', 'ER', 'IPO', 'MILF', 'BUT', 'SSN', 'FIFA', 'USD', 'CPU', 'AT', 'GG', 'Mar'}\n",
    "\n",
    "# Adding wsb/reddit flavor to vader to improve sentiment analysis, score: 4.0 to -4.0\n",
    "new_words = {\n",
    "    'citron': -4.0,  \n",
    "    'hidenburg': -4.0,        \n",
    "    'moon': 4.0,\n",
    "    'highs': 2.0,\n",
    "    'mooning': 4.0,\n",
    "    'long': 2.0,\n",
    "    'short': -2.0,\n",
    "    'call': 4.0,\n",
    "    'calls': 4.0,    \n",
    "    'put': -4.0,\n",
    "    'puts': -4.0,    \n",
    "    'break': 2.0,\n",
    "    'tendie': 2.0,\n",
    "     'tendies': 2.0,\n",
    "     'town': 2.0,     \n",
    "     'overvalued': -3.0,\n",
    "     'undervalued': 3.0,\n",
    "     'buy': 4.0,\n",
    "     'sell': -4.0,\n",
    "     'gone': -1.0,\n",
    "     'gtfo': -1.7,\n",
    "     'paper': -1.7,\n",
    "     'bullish': 3.7,\n",
    "     'bearish': -3.7,\n",
    "     'bagholder': -1.7,\n",
    "     'stonk': 1.9,\n",
    "     'green': 1.9,\n",
    "     'money': 1.2,\n",
    "     'print': 2.2,\n",
    "     'rocket': 2.2,\n",
    "     'bull': 2.9,\n",
    "     'bear': -2.9,\n",
    "     'pumping': -1.0,\n",
    "     'sus': -3.0,\n",
    "     'offering': -2.3,\n",
    "     'rip': -4.0,\n",
    "     'downgrade': -3.0,\n",
    "     'upgrade': 3.0,     \n",
    "     'maintain': 1.0,          \n",
    "     'pump': 1.9,\n",
    "     'hot': 1.5,\n",
    "     'drop': -2.5,\n",
    "     'rebound': 1.5,  \n",
    "     'crack': 2.5,}\n",
    "\n",
    "# Instantiate praw object\n",
    "reddit = praw.Reddit(\n",
    "    user_agent = \"Comment Extraction\",\n",
    "    client_id = \"QktIf3FZ10C5jg\",\n",
    "    client_secret = \"52XN7-d-s7tBO8Wld9mPQ19PMaV8HA\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(reddit, stocks, time):\n",
    "    \n",
    "    # Includes common words and words used on wsb that are also stock names\n",
    "    blacklist = {'I', 'ELON', 'WSB', 'THE', 'A', 'ROPE', 'YOLO', 'TOS', 'CEO', 'DD', 'IT', 'OPEN', 'ATH', 'PM', 'IRS', 'FOR','DEC', 'BE', 'IMO', 'ALL', 'RH', 'EV', 'TOS', 'CFO', 'CTO', 'DD', 'BTFD', 'WSB', 'OK', 'PDT', 'RH', 'KYS', 'FD', 'TYS', 'US', 'USA', 'IT', 'ATH', 'RIP', 'BMW', 'GDP', 'OTM', 'ATM', 'ITM', 'IMO', 'LOL', 'AM', 'BE', 'PR', 'PRAY', 'PT', 'FBI', 'SEC', 'GOD', 'NOT', 'POS', 'FOMO', 'TL;DR', 'EDIT', 'STILL', 'WTF', 'RAW', 'PM', 'LMAO', 'LMFAO', 'ROFL', 'EZ', 'RED', 'BEZOS', 'TICK', 'IS', 'PM', 'LPT', 'GOAT', 'FL', 'CA', 'IL', 'MACD', 'HQ', 'OP', 'PS', 'AH', 'TL', 'JAN', 'FEB', 'JUL', 'AUG', 'SEP', 'SEPT', 'OCT', 'NOV', 'FDA', 'IV', 'ER', 'IPO', 'MILF', 'BUT', 'SSN', 'FIFA', 'USD', 'CPU', 'AT', 'GG', 'Mar'}\n",
    "\n",
    "    # Adding wsb/reddit flavor to vader to improve sentiment analysis, score: 4.0 to -4.0\n",
    "    new_words = {\n",
    "        'citron': -4.0,  \n",
    "        'hidenburg': -4.0,        \n",
    "        'moon': 4.0,\n",
    "        'highs': 2.0,\n",
    "        'mooning': 4.0,\n",
    "        'long': 2.0,\n",
    "        'short': -2.0,\n",
    "        'call': 4.0,\n",
    "        'calls': 4.0,    \n",
    "        'put': -4.0,\n",
    "        'puts': -4.0,    \n",
    "        'break': 2.0,\n",
    "        'tendie': 2.0,\n",
    "         'tendies': 2.0,\n",
    "         'town': 2.0,     \n",
    "         'overvalued': -3.0,\n",
    "         'undervalued': 3.0,\n",
    "         'buy': 4.0,\n",
    "         'sell': -4.0,\n",
    "         'gone': -1.0,\n",
    "         'gtfo': -1.7,\n",
    "         'paper': -1.7,\n",
    "         'bullish': 3.7,\n",
    "         'bearish': -3.7,\n",
    "         'bagholder': -1.7,\n",
    "         'stonk': 1.9,\n",
    "         'green': 1.9,\n",
    "         'money': 1.2,\n",
    "         'print': 2.2,\n",
    "         'rocket': 2.2,\n",
    "         'bull': 2.9,\n",
    "         'bear': -2.9,\n",
    "         'pumping': -1.0,\n",
    "         'sus': -3.0,\n",
    "         'offering': -2.3,\n",
    "         'rip': -4.0,\n",
    "         'downgrade': -3.0,\n",
    "         'upgrade': 3.0,     \n",
    "         'maintain': 1.0,          \n",
    "         'pump': 1.9,\n",
    "         'hot': 1.5,\n",
    "         'drop': -2.5,\n",
    "         'rebound': 1.5,  \n",
    "         'crack': 2.5,\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Set program parameters\n",
    "    subs = ['wallstreetbets', 'stocks', 'investing', 'stockmarket']     # sub-reddit to search\n",
    "    post_flairs = {'Daily Discussion', 'Weekend Discussion', 'Discussion'}    # posts flairs to search || None flair is automatically considered\n",
    "    goodAuth = {'AutoModerator'}   # authors whom comments are allowed more than once\n",
    "    uniqueCmt = True                # allow one comment per author per symbol\n",
    "    ignoreAuthP = {'example'}       # authors to ignore for posts \n",
    "    ignoreAuthC = {'example'}       # authors to ignore for comment \n",
    "    upvoteRatio = 0.95         # upvote ratio for post to be considered, 0.70 = 70% TASK: Revert back to 70%\n",
    "    ups = 20       # define # of upvotes, post is considered if upvotes exceed this\n",
    "    limit = 10      # define the limit, comments 'replace more' limit TASK: \n",
    "    upvotes = 2     # define # of upvotes, comment is considered if upvotes exceed this \n",
    "    picks = 10     # define # of picks here, prints as \"Top ## picks are:\"\n",
    "    picks_ayz = 10   # define # of picks for sentiment analysis\n",
    "\n",
    "    posts, count, c_analyzed, tickers, titles, a_comments = 0, 0, 0, {}, [], {}\n",
    "    cmt_auth = {}\n",
    "\n",
    "    for sub in subs:\n",
    "        subreddit = reddit.subreddit(sub)\n",
    "        hot_python = subreddit.hot() # sorting posts by hot\n",
    "        # Extracting comments, symbols from subreddit\n",
    "        for submission in hot_python:\n",
    "            flair = submission.link_flair_text\n",
    "            author = submission.author.name\n",
    "\n",
    "            # Checking: post upvote ratio # of upvotes, post flair, and author\n",
    "            if submission.upvote_ratio >= upvoteRatio and submission.ups > ups and (flair in post_flairs or flair is None) and author not in ignoreAuthP:\n",
    "                submission.comment_sort = 'new'\n",
    "                comments = submission.comments\n",
    "                titles.append(submission.title)\n",
    "                posts += 1\n",
    "                submission.comments.replace_more(limit = limit)\n",
    "                for comment in comments:\n",
    "                    # try except for deleted account? # TASK: What is this peice of code accomplishing?\n",
    "                    try:\n",
    "                        auth = comment.author.name\n",
    "                    except:\n",
    "                        pass\n",
    "                    c_analyzed += 1\n",
    "\n",
    "                    # checking: comment upvotes and author\n",
    "                    if comment.score > upvotes and auth not in ignoreAuthC:\n",
    "                        split = comment.body.split(' ')\n",
    "                        for word in split:\n",
    "                            word = word.replace(\"$\", \"\")\n",
    "                            # upper = ticker, length of ticker <= 5, excluded words\n",
    "                            if word.isupper() and len(word) <= 5 and word not in blacklist and word in stocks:\n",
    "\n",
    "                                # unique comments, try/except for key errors\n",
    "                                if uniqueCmt and auth not in goodAuth:\n",
    "                                    try:\n",
    "                                        if auth in cmt_auth[word]:\n",
    "                                            break\n",
    "                                    except:\n",
    "                                        pass\n",
    "\n",
    "                                # counting tickers\n",
    "                                if word in tickers:\n",
    "                                    tickers[word] += 1\n",
    "                                    a_comments[word].append(comment.body)\n",
    "                                    cmt_auth[word].append(auth)\n",
    "                                    count += 1\n",
    "                                else:\n",
    "                                    tickers[word] = 1\n",
    "                                    cmt_auth[word] = [auth]\n",
    "                                    a_comments[word] = [comment.body]\n",
    "                                    count += 1\n",
    "\n",
    "    # sorts the dictionary\n",
    "    symbols = dict(sorted(tickers.items(), key=lambda item: item[1], reverse = True))\n",
    "    top_picks = list(symbols.keys())[0:picks]\n",
    "    time = (time.time() - start_time)\n",
    "\n",
    "    # print top picks\n",
    "    print(\"It took {t:.2f} seconds to analyze {c} comments in {p} posts in {s} subreddits.\\n\".format(t=time,\n",
    "                                                                                                    c=c_analyzed,\n",
    "                                                                                                    p=posts,\n",
    "                                                                                                    s=len(subs)))\n",
    "    # Applying sentiment analysis\n",
    "    scores, s = {}, {}\n",
    "\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # adding custom words from data.py\n",
    "    vader.lexicon.update(new_words)\n",
    "    \n",
    "    picks_sentiment = list(symbols.keys())[0: picks_ayz]\n",
    "    for symbol in picks_sentiment:\n",
    "        stock_comments = a_comments[symbol]\n",
    "        for cmnt in stock_comments:\n",
    "            score = vader.polarity_scores(cmnt)\n",
    "            if symbol in s:\n",
    "                s[symbol][cmnt] = score\n",
    "            else:\n",
    "                s[symbol] = {cmnt: score}\n",
    "            if symbol in scores:\n",
    "                for key, _ in score.items():\n",
    "                    scores[symbol][key] += score[key]\n",
    "            else:\n",
    "                scores[symbol] = score\n",
    "\n",
    "        # calculating averages\n",
    "        for key in score:\n",
    "            scores[symbol][key] = scores[symbol][key] / symbols[symbol]\n",
    "            scores[symbol][key] = \"{pol:.3f}\".format(pol=scores[symbol][key])\n",
    "\n",
    "    # Printing sentiment analysis\n",
    "    print(f\"\\nSentiment analysis of top {picks_ayz} picks:\")\n",
    "    df = pd.DataFrame(scores)\n",
    "    df.index = ['Bearish', 'Neutral', 'Bullish', 'Total_Compound']\n",
    "    df = df.T\n",
    "    df['Stocks']=df.index\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop('index', axis=1, inplace=True)\n",
    "    df=df.reindex(columns=['Stocks', 'Bearish', 'Neutral', 'Bullish', 'Total_Compound'])\n",
    "    print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 205.74 seconds to analyze 406 comments in 7 posts in 4 subreddits.\n",
      "\n",
      "\n",
      "Sentiment analysis of top 10 picks:\n",
      "  Bearish Neutral Bullish Total_Compound Stocks\n",
      "0   0.114   0.791   0.095          0.039     CD\n",
      "1   0.022   0.894   0.084          0.352   COST\n",
      "2   0.056   0.918   0.025         -0.423   TSCO\n",
      "3   0.053   0.787   0.161          0.979    AMD\n",
      "4   0.104   0.731   0.165          0.618   TEAM\n",
      "5   0.000   1.000   0.000          0.000   CASH\n",
      "6   0.024   0.936   0.039          0.303   AAPL\n",
      "7   0.000   0.858   0.142          0.586   FSLR\n",
      "8   0.000   0.958   0.042          0.477   SBUX\n",
      "9   0.053   0.850   0.097          0.296   TMUS\n"
     ]
    }
   ],
   "source": [
    "df=get_data(reddit=reddit, stocks=stocks, time=time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "85676b5b98064dc67740f0fe05b014afeeee6e0f81ace4500c826ea813768386"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
